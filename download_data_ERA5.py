from datetime import datetime, timedelta
import cdsapi
import numpy as np
import xarray as xr
import os
import pandas as pd
from collections import defaultdict


c = cdsapi.Client(
    url='https://cds.climate.copernicus.eu/api',
    key='d1c02362-b7bf-453b-9da4-ce9ddad97925'
)

def download_surface_part1(filename, day, month, hour):
    """
    –°–∫–∞—á–∏–≤–∞–µ—Ç surface-–ø–æ–ª—è ERA5 –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–µ datetime (—à–∞–≥ 6 —á–∞—Å–æ–≤),
    –∑–∞—Ç–µ–º —É–¥–∞–ª—è–µ—Ç –ª–∏—à–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏.
    """
    print('üì• –°–∫–∞—á–∏–≤–∞–Ω–∏–µ surface-–ø–æ–ª–µ–π ERA5...')

    c.retrieve(
        'reanalysis-era5-single-levels',
        {
            'product_type': 'reanalysis',
            'variable': [
                'geopotential',
                'land_sea_mask',
                '2m_temperature',
                'mean_sea_level_pressure',
                '10m_v_component_of_wind',
                '10m_u_component_of_wind',
            ],
            'year': '2025',
            'month': month,
            'day': day,
            'time': hour,
            'format': 'netcdf',
            'grid': [1.0, 1.0],
            #'area': [66.5, 5.0, 48.5, 35.0],  # [North, West, South, East]
        },
        filename
    )

    print(f'‚úÖ –°–∫–∞—á–∏–≤–∞–Ω–∏–µ surface_part1 –∑–∞–≤–µ—Ä—à–µ–Ω–æ ‚Üí {filename}')

def change_part1(filename):
    ds = xr.load_dataset(filename, decode_timedelta=True)

    # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
    ds = ds.rename({
        "valid_time": "time",
        "latitude": "lat",
        "longitude": "lon",
        "z": "geopotential_at_surface",
        "lsm": "land_sea_mask",
        "t2m": "2m_temperature",
        "msl": "mean_sea_level_pressure",
        "v10": "10m_v_component_of_wind",
        "u10": "10m_u_component_of_wind",
    })

    # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—å batch
    ds = ds.expand_dims(dim={"batch": [0]})

    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º time –≤ timedelta64[ns]
    base_time = ds.time.values[0]
    time_delta = ds.time.values - base_time
    ds = ds.assign_coords(time=time_delta)

    # –î–æ–±–∞–≤–ª—è–µ–º datetime –∏ –¥–µ–ª–∞–µ–º –µ–≥–æ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ–π
    datetime = ds.time.values + base_time
    ds["datetime"] = (("batch", "time"), np.expand_dims(datetime, axis=0))
    ds = ds.set_coords("datetime")

    # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ (–µ—Å–ª–∏ –µ—Å—Ç—å)
    ds = ds.drop_vars(["number", "expver"], errors="ignore")

    # –ú–µ–Ω—è–µ–º –ø–æ—Ä—è–¥–æ–∫ –æ—Å–µ–π —É –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
    ds["geopotential_at_surface"] = ds["geopotential_at_surface"].transpose("batch", "time", "lat", "lon")
    ds["land_sea_mask"] = ds["land_sea_mask"].transpose("batch", "time", "lat", "lon")
    ds["2m_temperature"] = ds["2m_temperature"].transpose("batch", "time", "lat", "lon")
    ds["mean_sea_level_pressure"] = ds["mean_sea_level_pressure"].transpose("batch", "time", "lat", "lon")
    ds["10m_v_component_of_wind"] = ds["10m_v_component_of_wind"].transpose("batch", "time", "lat", "lon")
    ds["10m_u_component_of_wind"] = ds["10m_u_component_of_wind"].transpose("batch", "time", "lat", "lon")

    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —à–∏—Ä–æ—Ç–µ
    ds = ds.sortby("lat")

    # –ü—Ä–∏–≤–æ–¥–∏–º lat/lon –∫ float32
    ds = ds.assign_coords({
        "lat": ds["lat"].astype(np.float32),
        "lon": ds["lon"].astype(np.float32)
    })

    # –û–±—Ä–µ–∑–∞–µ–º –¥–æ –ø–µ—Ä–≤—ã—Ö 6 –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —à–∞–≥–æ–≤
    # ds = ds.isel(time=slice(0, 42))

    # –£–¥–∞–ª—è–µ–º batch –∏–∑ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç (–¥–µ–ª–∞–µ–º –∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª–µ)
    if "batch" in ds.coords:
        ds = ds.swap_dims({"batch": "batch"})  # —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å
        ds = ds.drop_vars("batch")  # —É–±–∏—Ä–∞–µ–º –∫–∞–∫ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—É

    # –£–±–∏—Ä–∞–µ–º time –∏ batch –∏–∑ geopotential_at_surface –∏ land_sea_mask
    if set(ds["geopotential_at_surface"].dims) == {"batch", "time", "lat", "lon"}:
        ds["geopotential_at_surface"] = ds["geopotential_at_surface"].isel(batch=0, time=0)
    if set(ds["land_sea_mask"].dims) == {"batch", "time", "lat", "lon"}:
        ds["land_sea_mask"] = ds["land_sea_mask"].isel(batch=0, time=0)

    print('–û–±—Ä–∞–±–æ—Ç–∫–∞ ds_surface_part1 –∑–∞–≤–µ—Ä—à–µ–Ω–∞')

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    ds.to_netcdf(filename, format="NETCDF4_CLASSIC")




def download_surface_part2(filename, day, month, hour):
    """
        –°–∫–∞—á–∏–≤–∞–µ—Ç surface-–ø–æ–ª—è ERA5 –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–µ datetime (—à–∞–≥ 6 —á–∞—Å–æ–≤)
        """
    print('üì• –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (single-levels_part2)...')

    c.retrieve(
        'reanalysis-era5-single-levels',
        {
            'product_type': 'reanalysis',
            'variable': [
                'total_precipitation',
                'toa_incident_solar_radiation'
            ],
            'year': '2025',
            'month': month,
            'day': day,
            'time': hour,
            'format': 'netcdf',
            'grid': [1.0, 1.0],
            #'area': [66.5, 5.0, 48.5, 35.0],  # [North, West, South, East]
        },
        filename
    )
    print(f'‚úÖ –°–∫–∞—á–∏–≤–∞–Ω–∏–µ surface_part2 –∑–∞–≤–µ—Ä—à–µ–Ω–æ ‚Üí {filename}')

def change_part2(filename):
    ds = xr.load_dataset(filename, decode_timedelta=True)

    # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
    ds = ds.rename({
        "valid_time": "time",
        "tp": "total_precipitation_6hr",
        "latitude": "lat",
        "longitude": "lon",
        "tisr": "toa_incident_solar_radiation"
    })

    # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—å batch
    ds = ds.expand_dims(dim={"batch": [0]})

    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º time –≤ timedelta64[ns]
    base_time = ds.time.values[0]
    time_delta = ds.time.values - base_time
    ds = ds.assign_coords(time=time_delta)

    # –î–æ–±–∞–≤–ª—è–µ–º datetime –∏ –¥–µ–ª–∞–µ–º –µ–≥–æ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ–π
    datetime = ds.time.values + base_time
    ds["datetime"] = (("batch", "time"), np.expand_dims(datetime, axis=0))
    ds = ds.set_coords("datetime")

    # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ (–µ—Å–ª–∏ –µ—Å—Ç—å)
    ds = ds.drop_vars(["number", "expver"], errors="ignore")

    # –ú–µ–Ω—è–µ–º –ø–æ—Ä—è–¥–æ–∫ –æ—Å–µ–π —É –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
    ds["toa_incident_solar_radiation"] = ds["toa_incident_solar_radiation"].transpose("batch", "time", "lat", "lon")
    ds["total_precipitation_6hr"] = ds["total_precipitation_6hr"].transpose("batch", "time", "lat", "lon")

    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —à–∏—Ä–æ—Ç–µ
    ds = ds.sortby("lat")

    # –ü—Ä–∏–≤–æ–¥–∏–º lat/lon –∫ float32
    ds = ds.assign_coords({
        "lat": ds["lat"].astype(np.float32),
        "lon": ds["lon"].astype(np.float32)
    })

    # –û–±—Ä–µ–∑–∞–µ–º –¥–æ –ø–µ—Ä–≤—ã—Ö 6 –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —à–∞–≥–æ–≤
    # ds = ds.isel(time=slice(0, 42))

    # –£–¥–∞–ª—è–µ–º batch –∏–∑ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç (–¥–µ–ª–∞–µ–º –∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª–µ)
    if "batch" in ds.coords:
        ds = ds.swap_dims({"batch": "batch"})  # —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å
        ds = ds.drop_vars("batch")  # —É–±–∏—Ä–∞–µ–º –∫–∞–∫ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—É

    print('–û–±—Ä–∞–±–æ—Ç–∫–∞ ds_surface_part2 –∑–∞–≤–µ—Ä—à–µ–Ω–∞')

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    ds.to_netcdf(filename, format="NETCDF4_CLASSIC")


def download_pressure_part1(filename, day, month, hour):
    """
            –°–∫–∞—á–∏–≤–∞–µ—Ç surface-–ø–æ–ª—è ERA5 –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–µ datetime (—à–∞–≥ 6 —á–∞—Å–æ–≤)
            """
    print('üì• –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (pressure-levels_part1)...')

    c.retrieve(
        'reanalysis-era5-pressure-levels',
        {
            'product_type': 'reanalysis',
            'variable': [
                'temperature',
                'geopotential',
                'u_component_of_wind',
                'v_component_of_wind',
                'vertical_velocity',
                'specific_humidity',
            ],
            'pressure_level': [
                '50', '100', '150', '200', '250', '300', '400', '500',
                '600', '700', '850', '925', '1000',
            ],
            'year': '2025',
            'month': month,
            'day': day,
            'time': hour,
            'format': 'netcdf',
            'grid': [1.0, 1.0],
            #'area': [66.5, 5.0, 48.5, 35.0],  # [North, West, South, East]     'area': [90, 0, -90, 359],
        },
        filename
    )
    print(f'‚úÖ –°–∫–∞—á–∏–≤–∞–Ω–∏–µ pressure_part1 –∑–∞–≤–µ—Ä—à–µ–Ω–æ ‚Üí {filename}')

def change_pressure_part1(filename):
    ds = xr.load_dataset(filename, decode_timedelta=True)

    # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
    ds = ds.rename({
        "z": "geopotential",
        "w": "vertical_velocity",
        "latitude": "lat",
        "longitude": "lon",
        "valid_time": "time",
        "v": "v_component_of_wind",
        "u": "u_component_of_wind",
        "t": "temperature",
        "q": "specific_humidity",
        "pressure_level": "level"
    })

    # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—å batch
    ds = ds.expand_dims(dim={"batch": [0]})

    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º time –≤ timedelta64[ns]
    base_time = ds.time.values[0]
    time_delta = ds.time.values - base_time
    ds = ds.assign_coords(time=time_delta)

    # –î–æ–±–∞–≤–ª—è–µ–º datetime –∏ –¥–µ–ª–∞–µ–º –µ–≥–æ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ–π
    datetime = ds.time.values + base_time
    ds["datetime"] = (("batch", "time"), np.expand_dims(datetime, axis=0))
    ds = ds.set_coords("datetime")

    # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ (–µ—Å–ª–∏ –µ—Å—Ç—å)
    ds = ds.drop_vars(["number", "expver"], errors="ignore")

    # –ú–µ–Ω—è–µ–º –ø–æ—Ä—è–¥–æ–∫ –æ—Å–µ–π —É –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
    ds["u_component_of_wind"] = ds["u_component_of_wind"].transpose("batch", "time", "level", "lat", "lon")
    # ds["total_precipitation_6hr"] = ds["total_precipitation_6hr"].transpose("batch", "time", "lat", "lon")

    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —à–∏—Ä–æ—Ç–µ
    ds = ds.sortby("lat")

    # O—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —É—Ä–æ–≤–µ–Ω—å –¥–∞–≤–ª–µ–Ω–∏—è –ø–æ –≤–æ–∑—Ä–∞—Å—Ç–∞–Ω–∏—é
    ds = ds.sortby("level")

    # –ü—Ä–∏–≤–æ–¥–∏–º lat/lon –∫ float32
    ds = ds.assign_coords({
        "lat": ds["lat"].astype(np.float32),
        "lon": ds["lon"].astype(np.float32)
    })

    # –û–±—Ä–µ–∑–∞–µ–º –¥–æ –ø–µ—Ä–≤—ã—Ö 6 –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —à–∞–≥–æ–≤
    # ds = ds.isel(time=slice(0, 42))

    # –£–¥–∞–ª—è–µ–º batch –∏–∑ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç (–¥–µ–ª–∞–µ–º –∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª–µ)
    if "batch" in ds.coords:
        ds = ds.swap_dims({"batch": "batch"})  # —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å
        ds = ds.drop_vars("batch")  # —É–±–∏—Ä–∞–µ–º –∫–∞–∫ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—É

    print('–û–±—Ä–∞–±–æ—Ç–∫–∞ era5_pressure_part1.nc –∑–∞–≤–µ—Ä—à–µ–Ω–∞')

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    ds.to_netcdf(filename, format="NETCDF4_CLASSIC")
    print('—Å–æ—Ö—Ä–∞–Ω–∏–ª–∏ —Ñ–∞–π–ª ')


def join_files(date):
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∞–π–ª—ã
    surface1 = xr.open_dataset(f"temp/era5_surface_part1.nc", decode_timedelta=True)
    surface2 = xr.open_dataset(f"temp/era5_surface_part2.nc", decode_timedelta=True)
    pressure = xr.open_dataset(f"temp/era5_pressure_part1.nc", decode_timedelta=True)

    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ —Å —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –∏–∑–º–µ—Ä–µ–Ω–∏—è–º–∏ (–µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å)
    # for ds in [surface1, surface2, pressure]:
    #    for var in ["geopotential_at_surface", "land_sea_mask"]:
    #        if var in ds:
    #            ds[var] = ds[var].isel(batch=0, time=0)

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤ –æ–¥–∏–Ω Dataset
    ds_merged = xr.merge([surface1, surface2, pressure], compat="override")

    # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ —Å–ª—É–∂–µ–±–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ, –µ—Å–ª–∏ –µ—Å—Ç—å
    ds_merged = ds_merged.drop_vars(["number", "expver", "toa_incident_solar_radiation"],
                                    errors="ignore")  # , "toa_incident_solar_radiation"

    print(f"‚úÖ –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ surface1, surface2, pressure1 –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª")
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
    output_file = f"w:/Postprocesing/Oleh Bedenok/GRAPHCAST/NOAA/TEST_Graphcast_14,05,2025-31,05,2025/data_ERA5/era5_{date}.nc"
    ds_merged.to_netcdf(output_file, format="NETCDF3_CLASSIC")

    print(f"‚úÖ –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ —Ñ–∞–π–ª: {output_file}")


def add_targets(date):
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª
    ds = xr.open_dataset("temp/out_file.nc", decode_timedelta=True)

    # –ü–æ–ª—É—á–∏–º —à–∞–≥ –≤—Ä–µ–º–µ–Ω–∏ (timedelta)
    time_step = ds.time[1].item() - ds.time[0].item()
    datetime_step = pd.to_datetime(ds.datetime.values[0, 1]) - pd.to_datetime(ds.datetime.values[0, 0])

    # –°–∫–æ–ª—å–∫–æ –Ω–æ–≤—ã—Ö —à–∞–≥–æ–≤ –¥–æ–±–∞–≤–∏–º
    n_new = 50

    # –ù–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–∏ –∏ –¥–∞—Ç—ã
    new_time = ds.time.values[-1] + time_step * np.arange(1, n_new + 1)
    new_datetime = pd.to_datetime(ds.datetime.values[0, -1]) + datetime_step * np.arange(1, n_new + 1)

    # –°–æ–∑–¥–∞–¥–∏–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ —Å NaN —Ç–æ–ª—å–∫–æ –¥–ª—è –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö, —É –∫–æ—Ç–æ—Ä—ã—Ö –µ—Å—Ç—å –∏–∑–º–µ—Ä–µ–Ω–∏–µ "time"
    new_data_vars = {}
    for var in ds.data_vars:
        da = ds[var]
        if "time" in da.dims:
            dims = da.dims
            shape = list(da.shape)
            shape[dims.index("time")] = n_new  # –∑–∞–º–µ–Ω–∏–º —Ä–∞–∑–º–µ—Ä –æ—Å–∏ –≤—Ä–µ–º–µ–Ω–∏

            # –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã, –∫—Ä–æ–º–µ "datetime", –∏–Ω–∞—á–µ –±—É–¥–µ—Ç –æ—à–∏–±–∫–∞ –ø—Ä–∏ concat
            coords = {k: v for k, v in da.coords.items() if k in dims and k != "datetime"}
            coords["time"] = new_time

            new_da = xr.DataArray(
                data=np.full(shape, np.nan, dtype=da.dtype),
                dims=dims,
                coords=coords
            )

            # –£–±–∏—Ä–∞–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ —Å–ª–∏—è–Ω–∏—è
            if "datetime" in da.coords:
                da = da.reset_coords(names="datetime", drop=True)

            # –û–±—ä–µ–¥–∏–Ω—è–µ–º
            new_data_vars[var] = xr.concat([da, new_da], dim="time")
        else:
            new_data_vars[var] = da  # –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º time –∏ datetime –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
    new_time_full = np.concatenate([ds.time.values, new_time])
    new_datetime_full = np.concatenate([ds.datetime.values[0], new_datetime])
    datetime_expanded = np.expand_dims(new_datetime_full, axis=0)

    # –°–æ–∑–¥–∞—ë–º –∏—Ç–æ–≥–æ–≤—ã–π Dataset
    ds_out = xr.Dataset(new_data_vars)
    ds_out = ds_out.assign_coords(time=("time", new_time_full))
    ds_out = ds_out.assign_coords(datetime=(("batch", "time"), datetime_expanded))

    # –µ—Å–ª–∏ batch –±—ã–ª–∞ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ–π
    if "batch" in ds.coords:
        ds_out = ds_out.assign_coords(batch=ds.coords["batch"])

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    ds_out.to_netcdf(f"w:/Postprocesing/Oleh Bedenok/GRAPHCAST/data_dla_tests/out_file_for_graphcast_{date}.nc", format="NETCDF3_CLASSIC")
    print(f"‚úÖ –ì–æ—Ç–æ–≤–æ: –¥–∞–Ω–Ω—ã–µ —Ä–∞—Å—à–∏—Ä–µ–Ω—ã –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ w:/Postprocesing/Oleh Bedenok/GRAPHCAST/data_dla_tests/out_file_for_graphcast_{date}.nc")


#dict_keys = ['23/01_18', '24/01_06', '24/01_18', '25/01_06', '25/01_18', '26/01_06', '26/01_18', '27/01_06', '27/01_18', '28/01_06', '28/01_18', '29/01_06', '29/01_18', '30/01_06', '30/01_18', '31/01_06', '31/01_18', '01/02_06', '01/02_18', '02/02_06', '02/02_18', '03/02_06', '03/02_18', '04/02_06', '04/02_18', '05/02_06', '05/02_18', '06/02_06', '06/02_18', '07/02_06', '07/02_18', '08/02_06', '08/02_18', '09/02_06', '09/02_18', '10/02_06', '10/02_18', '11/02_06', '11/02_18', '12/02_06', '12/02_18', '13/02_06', '13/02_18', '14/02_06', '14/02_18', '15/02_06', '15/02_18', '16/02_06', '16/02_18', '17/02_06', '17/02_18', '18/02_06', '18/02_18', '19/02_06', '19/02_18', '20/02_06', '20/02_18', '21/02_06', '21/02_18', '22/02_06', '22/02_18', '23/02_06', '23/02_18', '24/02_06', '24/02_18', '25/02_06', '25/02_18', '26/02_06', '26/02_18', '27/02_06', '27/02_18', '28/02_06', '28/02_18', '01/03_06', '01/03_18', '02/03_06', '02/03_18', '03/03_06', '03/03_18', '04/03_06', '04/03_18', '05/03_06', '05/03_18', '06/03_06', '06/03_18', '07/03_06', '07/03_18', '08/03_06', '08/03_18', '09/03_06', '09/03_18', '10/03_06', '10/03_18', '11/03_06', '11/03_18', '12/03_06', '12/03_18', '13/03_06', '13/03_18', '14/03_06', '14/03_18', '15/03_06', '15/03_18', '16/03_06', '16/03_18', '17/03_06', '17/03_18', '18/03_06', '18/03_18', '19/03_06', '19/03_18', '20/03_06', '20/03_18', '21/03_06', '21/03_18', '22/03_06', '22/03_18', '23/03_06', '23/03_18', '24/03_06', '24/03_18', '25/03_06', '25/03_18', '26/03_06', '26/03_18', '27/03_06', '27/03_18', '28/03_06', '28/03_18', '29/03_06', '29/03_18', '30/03_06', '30/03_18', '31/03_06', '31/03_18', '01/04_06', '01/04_18', '02/04_06', '02/04_18', '03/04_06', '03/04_18', '04/04_06', '04/04_18', '05/04_06', '05/04_18', '06/04_06', '06/04_18', '07/04_06', '07/04_18', '08/04_06', '08/04_18', '09/04_06', '09/04_18', '10/04_06', '10/04_18', '11/04_06']
#dict_keys = ['23/01_18', '24/01_06', '24/01_18', '25/01_06', '25/01_18', '26/01_06', '26/01_18', '27/01_06', '27/01_18', '28/01_06', '28/01_18', '29/01_06', '29/01_18', '30/01_06', '30/01_18', '31/01_06', '31/01_18', '01/02_06', '01/02_18', '02/02_06', '02/02_18', '03/02_06', '03/02_18', '04/02_06', '04/02_18', '05/02_06', '05/02_18', '06/02_06', '06/02_18', '07/02_06', '07/02_18', '08/02_06', '08/02_18', '09/02_06', '09/02_18', '10/02_06', '10/02_18', '11/02_06', '11/02_18', '12/02_06', '12/02_18', '13/02_06', '13/02_18', '14/02_06', '14/02_18', '15/02_06', '15/02_18', '16/02_06', '16/02_18', '17/02_06', '17/02_18', '18/02_06', '18/02_18', '19/02_06', '19/02_18', '20/02_06', '20/02_18', '21/02_06', '21/02_18', '22/02_06', '22/02_18', '23/02_06', '23/02_18', '24/02_06', '24/02_18', '25/02_06', '25/02_18', '26/02_06', '26/02_18', '27/02_06', '27/02_18', '28/02_06', '28/02_18', '01/03_06', '01/03_18', '02/03_06', '02/03_18', '03/03_06', '03/03_18', '04/03_06', '04/03_18', '05/03_06', '05/03_18', '06/03_06', '06/03_18', '07/03_06', '07/03_18', '08/03_06', '08/03_18', '09/03_06', '09/03_18', '10/03_06', '10/03_18', '11/03_06', '11/03_18', '12/03_06', '12/03_18', '13/03_06', '13/03_18', '14/03_06', '14/03_18', '15/03_06', '15/03_18', '16/03_06', '16/03_18', '17/03_06', '17/03_18', '18/03_06', '18/03_18', '19/03_06', '19/03_18', '20/03_06', '20/03_18', '21/03_06', '21/03_18', '22/03_06', '22/03_18', '23/03_06', '23/03_18', '24/03_06', '24/03_18', '25/03_06', '25/03_18', '26/03_06', '26/03_18', '27/03_06', '27/03_18', '28/03_06', '28/03_18', '29/03_06', '29/03_18', '30/03_06', '30/03_18', '31/03_06', '31/03_18', '01/04_06', '01/04_18', '02/04_06', '02/04_18', '03/04_06', '03/04_18', '04/04_06', '04/04_18', '05/04_06', '05/04_18', '06/04_06', '06/04_18', '07/04_06', '07/04_18', '08/04_06', '08/04_18', '09/04_06', '09/04_18', '10/04_06', '10/04_18', '11/04_06']
dict_keys = ['25/05_06', '25/05_18', '26/05_06', '26/05_18', '27/05_06', '27/05_18', '28/05_06', '28/05_18', '29/05_06', '29/05_18', '30/05_06', '30/05_18', '31/05_06', '31/05_18']

#dict_keys = [k for k in dict_keys if k.endswith('_06')]

for date in dict_keys:
    # –†–∞–∑–¥–µ–ª—è–µ–º
    date_part, hour = date.split('_')
    day, month = map(int, date_part.split('/'))
    hour = int(hour)

    # –ö–æ–ª-–≤–æ –¥–Ω–µ–π
    num_days = 13

    # –°–æ–∑–¥–∞—ë–º –æ–±—ä–µ–∫—Ç datetime (–≥–æ–¥ –º–æ–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å –ª—é–±–æ–π, –Ω–∞–ø—Ä–∏–º–µ—Ä, 2025)
    dt = datetime(year=2025, month=month, day=day)

    # –°–ª–æ–≤–∞—Ä—å, –≥–¥–µ –∫–ª—é—á ‚Äî –º–µ—Å—è—Ü, –∑–Ω–∞—á–µ–Ω–∏–µ ‚Äî —Å–ø–∏—Å–æ–∫ –¥–Ω–µ–π
    result = defaultdict(list)

    for i in range(num_days):
        current = dt + timedelta(days=i)
        month = current.strftime('%m')  # '01', '02', ...
        day = current.strftime('%d')  # '28', '29', ...
        result[month].append(day)

    # –í—ã–≤–æ–¥
    # –∑–∞–º–µ–Ω–∏—Ç—å / –Ω–∞ _
    date = date.replace('/', '_')
    x = 1
    for month in result:
        print(f"month ['{month}'] day {result[month]}")
        day_str = result[month]
        month_str = month
        times_str = ['00:00', '06:00', '12:00', '18:00']

        download_surface_part1("temp/era5_surface_part1.nc", day_str, month_str, times_str)
        change_part1("temp/era5_surface_part1.nc")

        download_surface_part2("temp/era5_surface_part2.nc", day_str, month_str, times_str)
        change_part2("temp/era5_surface_part2.nc")

        download_pressure_part1("temp/era5_pressure_part1.nc", day_str, month_str, times_str)
        change_pressure_part1("temp/era5_pressure_part1.nc")

        join_files(f'{date}_{x}')

        #add_targets(f'{date}_{x}')

        x += 1